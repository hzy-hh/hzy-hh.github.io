<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ACT for RNN和Universal Transformer的笔记</title>
      <link href="/2020/09/13/act-for-rnn-he-universal-transformer-de-bi-ji/"/>
      <url>/2020/09/13/act-for-rnn-he-universal-transformer-de-bi-ji/</url>
      
        <content type="html"><![CDATA[<p><img src="0.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>capsule layer和disentangled layer的处理非常像</title>
      <link href="/2020/09/02/capsule-layer-he-disentangled-layer-de-chu-li-fei-chang-xiang/"/>
      <url>/2020/09/02/capsule-layer-he-disentangled-layer-de-chu-li-fei-chang-xiang/</url>
      
        <content type="html"><![CDATA[<p>Disentangled Graph Convolutional Networks和Dynamic Routing Between Capsules</p><p>均为EM算法</p><p><img src="0.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cv </tag>
            
            <tag> graph </tag>
            
            <tag> capsule </tag>
            
            <tag> disentangled </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>postcapsule networks笔记</title>
      <link href="/2020/09/02/postcapsule-networks-bi-ji/"/>
      <url>/2020/09/02/postcapsule-networks-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>论文地址：<a href="https://arxiv.org/pdf/1710.09829v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1710.09829v1.pdf</a></p><p>中文讲解：<a href="https://kexue.fm/archives/4819" target="_blank" rel="noopener">https://kexue.fm/archives/4819</a></p><p>英文讲解：<a href="https://www.freecodecamp.org/news/understanding-capsule-networks-ais-alluring-new-architecture-bdb228173ddc/" target="_blank" rel="noopener">https://www.freecodecamp.org/news/understanding-capsule-networks-ais-alluring-new-architecture-bdb228173ddc/</a></p><p><img src="0.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cv </tag>
            
            <tag> capsule </tag>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</title>
      <link href="/2020/07/25/semi-supervised-classification-with-graph-convolutional-networks/"/>
      <url>/2020/07/25/semi-supervised-classification-with-graph-convolutional-networks/</url>
      
        <content type="html"><![CDATA[<h2 id="SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS-GCN"><a href="#SEMI-SUPERVISED-CLASSIFICATION-WITH-GRAPH-CONVOLUTIONAL-NETWORKS-GCN" class="headerlink" title="SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS(GCN)"></a><center><strong>SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS(GCN)</strong></center></h2><p>笔记学习自：</p><p>SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</p><p><a href="https://www.zhihu.com/question/54504471/answer/332657604" target="_blank" rel="noopener">https://www.zhihu.com/question/54504471/answer/332657604</a></p><p><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML2020/GNN.pdf" target="_blank" rel="noopener">http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML2020/GNN.pdf</a></p><h4 id="一、解决的问题"><a href="#一、解决的问题" class="headerlink" title="一、解决的问题"></a>一、解决的问题</h4><p>​        将卷积应用到图结构中，并进行半监督学习。</p><h4 id="二、研究的思路"><a href="#二、研究的思路" class="headerlink" title="二、研究的思路"></a>二、研究的思路</h4><p>​        前人用的graph-based semi-supervised learning含有smoothness assumption. This assumption, however, might restrict modeling capacity, as graph edges need not necessarily encode node similarity, but could contain additional information.</p><p><img src="%E5%9B%BE%E7%89%871.png" alt="前人的方法，含有λ项为控制平滑的惩罚项"></p><p>​        因此，我们想弄一个 graph structure which directly using a neural network model f(X, A) and train on a supervised target L0 for all nodes with labels, thereby avoiding explicit graph-based regularization in the loss function.</p><p>​        根据CNN的思想，我们也想对图结点进行卷积，并且所用的filter是公用的且只作用于图的一部分。论文中将图结点运用spectral方法转换到谱空间进行卷积在转换回去，转换时对图结点左乘normalized graph Laplacian的eigenvectors的转置转换到谱空间，然后进行卷积（卷积核为normalized graph Laplacian特征值构成的对角矩阵的函数），最后左乘normalized graph Laplacian的eigenvectors返回原空间完成卷积，如下图：（讲解spectral graph theory的视频<a href="https://www.youtube.com/watch?v=M9ht8vsVEw8&amp;feature=youtu.be）" target="_blank" rel="noopener">https://www.youtube.com/watch?v=M9ht8vsVEw8&amp;feature=youtu.be）</a></p><p><img src="%E5%9B%BE%E7%89%872.png" alt></p><p>​        然而此方法计算开销大（两个U相乘O(n^2)），且没有spatial localization，于是论文弄出一个Chebyshev多项式，将卷积核g改变，然后又神奇般的消掉了两个eigenvector U，不仅减少了计算开销，还实现了spatial localization，方法如下：</p><p>​        利用Chebyshev多项式代替原卷积核:</p><p><img src="%E5%9B%BE%E7%89%873.png" alt></p><p><img src="%E5%9B%BE%E7%89%874.png" alt></p><p><img src="%E5%9B%BE%E7%89%875.png" alt=" "></p><p>​        将新的卷积核代入原始，得：</p><p>​        <strong>Z=</strong><img src="%E5%9B%BE%E7%89%876.png" alt></p><p>​        因为Chebyshev多项式作用在对角矩阵上，不会影响矩阵运算。那就改变一下运算顺序，先把矩阵运算放进去(把两个U房间T的括号里)，又L = UΛU^T，得到：</p><p><img src="%E5%9B%BE%E7%89%877.png" alt></p><p>​        这样变换的好处在于：计算过程无需再进行特征向量分解，且可以k locolize。</p><p>于是完成了对图结点进行卷积，接下来大体要做的事就是仿射变换+非线性函数激活：</p><p>论文中，令k=1(相当于限定一个卷积核的大小)，并估算λmax≈2，于是：</p><p><img src="%E5%9B%BE%E7%89%878.png" alt></p><p>​        为了方便顺便抑制一下overfitting，我们令θ=θ0=-θ1，于是：</p><p><img src="%E5%9B%BE%E7%89%879.png" alt></p><p>​        接下来：</p><p><img src="%E5%9B%BE%E7%89%8710.png" alt></p><p>​        仿射变换完成了，最后就是非线性激活然后一层一层叠下去。（不过论文附录中的实验，不加risidual，叠了两三层以后性能就急剧下降，加了risidual也仅仅是维持维持）。最终GCN形式(两层)如下：</p><p><img src="%E5%9B%BE%E7%89%8711.png" alt></p><p>注：在预处理中,邻接矩阵A和度矩阵D都可以提前求出来，而结点的特征向量x又是已知的，所以只有权重矩阵W是参数，通过反向传播求得。</p><h4 id="三、主要贡献点"><a href="#三、主要贡献点" class="headerlink" title="三、主要贡献点"></a>三、主要贡献点</h4><p><img src="%E5%9B%BE%E7%89%8712.png" alt></p><p>我的疑问：</p><p>1、最开始用的eigenvalues组成的对角矩阵的函数的卷积核，论文用Chebyshev多项式来替代。像泰勒展开或者傅里叶级数，他们近似等于原函数都是在无限项的情况下，因此，直觉上来讲，这个Chebyshev多项式不也应该至少要有特征值个数那么多项，才能近似替代吧，原文中令K=1，即只用两项Chebyshev多项式来替代最开始用的eigenvalues组成的对角矩阵的函数的卷积核，这个时候还是近似的吗？或许数学上就是这样的吧，数学太难了。</p><p>2、为啥可以估算renormalized拉普拉斯矩阵的λmax≈2，是因为实际中的graph都是稀疏图吗？</p><p>3、实验部分没怎么看懂，对数据集不熟悉，且论文中提到哪个数据集照着之前哪个人那样处理的，我还没有去看怎么处理的。</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NLP</title>
      <link href="/2020/07/25/nlp/"/>
      <url>/2020/07/25/nlp/</url>
      
        <content type="html"><![CDATA[<p>Skip-Gram:<a href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/" target="_blank" rel="noopener">http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/</a></p><p>Transformer annotated with pytorch:<a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank" rel="noopener">http://nlp.seas.harvard.edu/2018/04/03/attention.html</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>二叉树序列知二求一</title>
      <link href="/2020/04/09/er-cha-shu-xu-lie-zhi-er-qiu-yi/"/>
      <url>/2020/04/09/er-cha-shu-xu-lie-zhi-er-qiu-yi/</url>
      
        <content type="html"><![CDATA[<p>决策树看的很烦，于是打算去刷一波二叉树的题。</p><p>参考自：<a href="https://blog.csdn.net/qq_44622401/article/details/104064901" target="_blank" rel="noopener">https://blog.csdn.net/qq_44622401/article/details/104064901</a></p><pre><code>#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;ctype.h&gt;#include &lt;stdbool.h&gt;#include &lt;string.h&gt;void print_post(char *pre, char *in, int root, int start, int end);void print_pre(char *post, char *in, int root, int start, int end);int main(){    char *pre = &quot;123456&quot;; // 前序    char *in = &quot;324165&quot;;  // 中序    char *post = &quot;342651&quot;; // 后序    print_post(pre, in, 0, 0, strlen(in) -1 );    printf(&quot;\n&quot;);    print_pre(post, in, strlen(post)-1, 0, strlen(in)-1);    printf(&quot;\n&quot;);    system(&quot;pause&quot;);    return 0;}void print_post( char *pre, char *in, int root, int start, int end){    if( start &gt; end )        return;    int i = start;    while(i&lt;end &amp;&amp; in[i] != pre[root]) // 在中序序列中找到根节点以分割左右子树        i++;    print_post(pre, in, root+1, start, i - 1 ); // 遍历左子树    print_post(pre, in, root+i-start+1, i+1, end); // 遍历右子树    printf(&quot;%c &quot;, pre[root]);    }void print_pre( char *post, char *in, int root, int start, int end){    if( start&gt;end )        return;    int i = start;    while( i&lt;end &amp;&amp; in[i]!=post[root] )        i++;    printf(&quot;%c &quot;, post[root]);    print_pre( post, in, root-end+i-1, start, i-1); // 遍历左子树    print_pre (post, in, root-1, i+1, end);}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>统计学习方法第一章小结</title>
      <link href="/2020/03/31/tong-ji-xue-xi-fang-fa-di-yi-zhang-xiao-jie/"/>
      <url>/2020/03/31/tong-ji-xue-xi-fang-fa-di-yi-zhang-xiao-jie/</url>
      
        <content type="html"><![CDATA[<h4 id="统计学习方法"><a href="#统计学习方法" class="headerlink" title="统计学习方法"></a>统计学习方法</h4><p><strong>统计学习方法概括</strong>：现在有某个输入输出的对应关系f无法轻易得知，于是给一堆训练数据给机器学习，让机器找到一个最优模型g（最契合f），使得不管是训练数据的输入还是未知数据的输入，通过g得到的输出结果与通过f得到的差别结果最小。</p><h4 id="统计学习分类"><a href="#统计学习分类" class="headerlink" title="统计学习分类"></a>统计学习分类</h4><p>1、 <strong>监督学习</strong>：从标注（如标注某些单词是名词，某些单词是动词）数据中学习预测模型的机器学习问题。  （标注耗费人工，但感觉准确率比无监督学习高？）<br>2、 <strong>无监督学习</strong>：数据没有标注，机器自己找规律。<br>半监督学习（两者间），主动学习（机器自己提问）<br>概率模型、非概率模型（取值0/1）、线性模型、非线性模型、参数化模型、非参数化模型（暂时不理解）<br>贝叶斯学习（后验概率=先验概率 * 调整比例）<br>核方法（将非线性模型的纬度提升使其线性可分，数学原理暂不理解）</p><h4 id="统计学习方法三要素"><a href="#统计学习方法三要素" class="headerlink" title="统计学习方法三要素"></a>统计学习方法三要素</h4><p>1、<strong>模型</strong>：在监督学习中，模型就是要学习的条件概率分布或决策函数，模型的假设空间为可能的条件概率或决策函数的集合。<br>2、<strong>策略</strong>：如何选取最优化的模型？损失函数最小（既预测值与真实值差距最小，可用0-1损失函数、平方损失函数、绝对损失函数、对数损失函数衡量）。学习的目标就是选择期望风险最小的模型（期望风险：每一对输入对应的输出与实际值的差值乘联合分布的积分）。由于期望风险不是上帝视角无法计算，于是只能通过局部推整体，从而出来了经验风险（训练数据集在某选取模型下的平均损失），当经验风险小是我们认为期望风险也应该小。然而，除非训练数据超级大，如果经验风险过小有可能导致过拟合，此时我们在经验风险的表达式后面添加一个正则化项变成结构风险，此时我们认为结构风险越小，期望风险越小。结构风险不同于经验风险，经验风险可以不断地增加选取模型的复杂度以更好地契合训练数据，而结构风险中，当模型的复杂度不断增加是，正则化的值也不断增加。因此，结构风险的意义就是：选取尽可能简单的模型尽可能提高准确率。<br>3、<strong>算法</strong>：算法指学习模型的具体计算方法，一般指求解最优化问题的方法。</p><h4 id="模型评估与模型选择"><a href="#模型评估与模型选择" class="headerlink" title="模型评估与模型选择"></a>模型评估与模型选择</h4><p>1、<strong>泛化能力</strong>：学习方法对未知数据的预测能力。<br>2、<strong>过拟合与模型选择</strong>：…<br>3、<strong>正则化与交叉验证</strong>：正则化…交叉验证：用的最多的是S折交叉验证：把数据分为S个互不相交、大小相同的自己，把S-1个子集的数据作为训练数据，剩下的作为测试数据，重复S次，选取平均误差最小的模型。<br>4、<strong>泛化误差上界</strong>：总的来说，样本容量越多，假设空间越小，泛化误差上界越小。<strong>针对二类泛化误差的数学原理有待理解</strong>。  </p><p>####第一章习题答案<br><a href="https://blog.csdn.net/breeze_blows/article/details/85544308" target="_blank" rel="noopener">https://blog.csdn.net/breeze_blows/article/details/85544308</a></p>]]></content>
      
      
      <categories>
          
          <category> 统计学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《统计学习方法》各章节代码实现与课后习题参考解答</title>
      <link href="/2020/03/30/tong-ji-xue-xi/"/>
      <url>/2020/03/30/tong-ji-xue-xi/</url>
      
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/breeze_blows/article/details/85469944" target="_blank" rel="noopener">https://blog.csdn.net/breeze_blows/article/details/85469944</a></p><p><a href="https://github.com/WenDesi/lihang_book_algorithm" target="_blank" rel="noopener">https://github.com/WenDesi/lihang_book_algorithm</a></p>]]></content>
      
      
      <categories>
          
          <category> 统计学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>串的模式匹配</title>
      <link href="/2020/02/18/chuan-de-mo-shi-pi-pei/"/>
      <url>/2020/02/18/chuan-de-mo-shi-pi-pei/</url>
      
        <content type="html"><![CDATA[<p> BF算法：<br><a href="https://www.csdn.net/gather_2e/MtTacg3sMDk0MC1ibG9n.html" target="_blank" rel="noopener">https://www.csdn.net/gather_2e/MtTacg3sMDk0MC1ibG9n.html</a></p><p>KMP算法：<a href="https://baike.baidu.com/item/kmp%E7%AE%97%E6%B3%95/10951804?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/kmp%E7%AE%97%E6%B3%95/10951804?fr=aladdin</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 串的模式匹配 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UVa232</title>
      <link href="/2020/01/26/uva232/"/>
      <url>/2020/01/26/uva232/</url>
      
        <content type="html"><![CDATA[<pre><code>\#include &lt;stdio.h&gt;\#include &lt;string.h&gt;\#include &lt;stdbool.h&gt;\#define maxr 12\#define maxc 12int main(){char map[maxr][maxc];int r, c;for (r = 0; r &lt; 10; r++){    gets(map[r]);    if (map[r][0] == &#39;0&#39;)        break;}c = strlen(map[0]);int number[r][c];memset(number, 0, r * c);int num = 1;for (int i = 0; i &lt; r; i++){    for (int j = 0; j &lt; c; j++)    {        if (map[i][j] == &#39;*&#39;)            continue;        if (i == 0 || map[i - 1][j] == &#39;*&#39; || (j &gt; 0 &amp;&amp; map[i][j - 1] == &#39;*&#39;))            number[i][j] = num++;    }}int space = 0;for (int i = 0; i &lt; r; i++){    int j;    for (j = 0; j &lt; c; j++)    {        if (map[i][j] != &#39;*&#39;)            break;    }    for (; j &lt; c; j++)    {        if (map[i][j] == &#39;*&#39;)        {            if (space == 0)            {                printf(&quot;\n&quot;);                space++;            }            continue;        }        printf(&quot;%c&quot;, map[i][j]);    }    printf(&quot;\n&quot;);}if (space == 0)    printf(&quot;\n&quot;);space = 0;for (int i = 0; i &lt; c; i++){    int j;    for (j = 0; j &lt; r; j++)    {        if (map[j][i] != &#39;*&#39;)            break;    }    for (; j &lt; r; j++)    {        if (map[j][i] == &#39;*&#39;)        {            if (space == 0)            {                printf(&quot;\n&quot;);                space++;            }            continue;        }        space = 0;        printf(&quot;%c&quot;, map[j][i]);    }    if (space == 0)        printf(&quot;\n&quot;);}getchar();return 0;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构与算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Uva202</title>
      <link href="/2020/01/26/uva202/"/>
      <url>/2020/01/26/uva202/</url>
      
        <content type="html"><![CDATA[<p>还有BUG，无法正确显示除得尽的小数和单个数字为循环节的小数</p><pre><code>#include&lt;stdio.h&gt;#include&lt;string.h&gt;int main(){int a,b,digit[55],r[3005];memset(r,0,3005);int t;scanf(&quot;%d&quot;,&amp;t);while(t--){    int count=0;     memset(r,0,3005);    scanf(&quot;%d%d&quot;,&amp;a,&amp;b);    digit[count++]=a/b;    while(!r[a-b*digit[count-1]]){         r[a-b*digit[count-1]]=1;        a=(a-digit[count-1]*b)*10;        digit[count++]=a/b;    }    printf(&quot;%d\n&quot;,count-1);    printf(&quot;%d.(&quot;,digit[0]);    for(int i=1;i&lt;count;i++){        printf(&quot;%d&quot;,digit[i]);    }    printf(&quot;)\n&quot;);}}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构与算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UVa1368</title>
      <link href="/2020/01/26/uva1368/"/>
      <url>/2020/01/26/uva1368/</url>
      
        <content type="html"><![CDATA[<pre><code>\#include &lt;stdio.h&gt;\#include &lt;string.h&gt;\#include &lt;stdbool.h&gt;\#define maxm 55\#define maxn 1005int main(){char arr[maxm][maxn];char best[maxn];int m, n;int min = 0;scanf(&quot;%d%d&quot;, &amp;m, &amp;n);for (int i = 0; i &lt; m; i++){    scanf(&quot;%s&quot;, arr[i]);}strcpy(best, arr[0]);int choose = 0;for (int i = 0; i &lt; m; i++){    for (int j = 0; j &lt; n; j++)    {        if (arr[choose][j] != arr[i][j])            min++;    }}int temp = 1;int distance;while (temp &lt;= m){    distance = 0;    for (int i = 0; i &lt; m; i++)    {        for (int j = 0; j &lt; n; j++)        {            if (arr[temp][j] != arr[i][j])                distance++;        }    }    if (distance == min &amp;&amp; strcmp(arr[temp], arr[choose]) &lt; 0)    {        min = distance;        choose = temp;    }    if (distance &lt; min)    {        min = distance;        choose = temp;    }    temp++;}printf(&quot;\n%d\n%s\n&quot;, min, arr[choose]);getchar();getchar();return 0;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构与算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UVa455</title>
      <link href="/2020/01/26/uva455/"/>
      <url>/2020/01/26/uva455/</url>
      
        <content type="html"><![CDATA[<pre><code>\#include &lt;stdio.h&gt;\#include &lt;string.h&gt;\#define maxn 85int main() //my answer{char str[maxn];scanf(&quot;%s&quot;,str);int len=strlen(str);for (int i=1;i&lt;=len/2;i++){    char min[i];    int judge=1;    for(int j=0;j&lt;i;j++){        min[j]=str[j];    }    for(int p=0;p&lt;len;p=p+i){        for(int q=0;q&lt;i;q++){            if(min[q]!=str[p+q]){                judge=0;                break;            }            if(judge==0) break;        }    }    if(judge==1){        printf(&quot;%d\n&quot;,i);        break;    }    if(i==len/2) printf(&quot;none\n&quot;);}    getchar();    getchar();    return 0;}/*                         internet\#include&lt;stdio.h&gt;\#include&lt;string.h&gt;\#include&lt;ctype.h&gt;\#define max 100+10char s[max];int main(){int n, len;scanf(&quot;%d&quot;, &amp;n);getchar();while (n--){    getchar();    gets(s);    len = strlen(s);    for (int i = 1; i &lt;= len;i++)    if (len%i == 0)    {        bool ok = true;        for (int j = i; j &lt; len;j++)        if (s[j] != s[j%i])        {            ok = false;            break;        }        if (ok)        {            printf(&quot;%d\n&quot;, i);            if (n)                putchar(&#39;\n&#39;);            break;        }    }}return 0;}    */</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构与算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UVa227</title>
      <link href="/2020/01/26/uva227/"/>
      <url>/2020/01/26/uva227/</url>
      
        <content type="html"><![CDATA[<pre><code>#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdbool.h&gt;#define maxn 25int main(){char map[5][5]={&#39;T&#39;,&#39;R&#39;,&#39;G&#39;,&#39;S&#39;,&#39;J&#39;,&#39;X&#39;,&#39;D&#39;,&#39;O&#39;,&#39;K&#39;,&#39;I&#39;,&#39;M&#39;,&#39; &#39;,&#39;V&#39;,&#39;L&#39;,&#39;N&#39;,&#39;W&#39;,&#39;P&#39;,&#39;A&#39;,&#39;B&#39;,&#39;E&#39;,&#39;U&#39;,&#39;Q&#39;,&#39;H&#39;,&#39;C&#39;,&#39;F&#39;};char command[maxn];int a=2,b=1;        bool judge=true;scanf(&quot;%s&quot;,command);int len=strlen(command);for(int i=0;i&lt;len;i++){ char temp;    switch (command[i]){        case &#39;A&#39;:            if(a==0){                judge=false;                break;            }         temp=map[a-1][b];         map[a-1][b]=map[a][b];         map[a][b]=temp;         a--;          break;        case &#39;B&#39;:            if(a==4){                judge=false;                break;            }          temp=map[a+1][b];         map[a+1][b]=map[a][b];         map[a][b]=temp;         a++;         break;         case &#39;L&#39;:            if(b==0){                judge=false;                break;            }            temp=map[a][b-1];           map[a][b-1]=map[a][b];          map[a][b]=temp;          b--;          break;          case &#39;R&#39;:            if(b==4){                judge=false;                break;            }             temp=map[a][b+1];           map[a][b+1]=map[a][b];          map[a][b]=temp;          b++;          break;    }    if(judge==false){        printf(&quot;This puzzle has no final configuration.\n&quot;);        break;    }}if(judge==true){    for(int i=0;i&lt;5;i++){        for(int j=0;j&lt;5;j++){            printf(&quot;%-2c&quot;,map[i][j]);        }        printf(&quot;\n&quot;);    }}getchar();getchar();return 0;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构与算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的小站建成啦！！！</title>
      <link href="/2020/01/25/xiao-zhan-jian-cheng/"/>
      <url>/2020/01/25/xiao-zhan-jian-cheng/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
